= if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.log.{ElasticTracing, TracedData} import com.homework.da.util._ import org.apache.spark.rdd.RDD import org.apache.spark.streaming.StreamingContext import org.apache.spark.streaming.dstream.DStream import org.fire.spark.streaming.core.plugins.kafka.KafkaDirectSource import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool import org.fire.spark.streaming.core.plugins.redis.RedisConnectionPool.safeClose import org.fire.spark.streaming.core.{FireStreaming, Logging} import redis.clients.jedis.Jedis import scala.util.{Failure, Success, Try} /** * Auther: wjxing * Date: 2019-03-02 20:57 * Package: * Description: OnlineState表更新redis到课时长 * * 此程序根据 OnlineStat 表进行 学员对应章节的到课时长计算,并将计算结果进行推送 * 凡是在此程序中收到进入，未收到退出的学员 其对应章节的到课时长 将在 * Lesson2Redis 和 LessonEnding2Redis 中进行收尾处理 * * homework_fudao.OnlineStat10 (有分表逻辑) * +---------+---------------------+------+-----+---------+----------------+ * | Field   | Type                | Null | Key | Default | Extra          | * +---------+---------------------+------+-----+---------+----------------+ * | id      | bigint(20) unsigned | NO   | PRI | NULL    | auto_increment | * | uid     | bigint(20) unsigned | NO   | MUL | NULL    |                | * | product | varchar(32)         | NO   |     | NULL    |                | * | extra   | varchar(256)        | YES  |     |         |                | * | cmdno   | int(6)              | NO   |     | NULL    |                | * | stime   | int(10) unsigned    | NO   |     | NULL    |                | * | utime   | int(10) unsigned    | NO   |     | NULL    |                | * | dt      | int(10) unsigned    | NO   | MUL | NULL    |                | * +---------+---------------------+------+-----+---------+----------------+ * * 需过滤product = fudao的数据 cmdno = 100011 进入 100010 退出 * extra字段内容 uid=2232623410&role=2&courseId=25989&lessonId=52527&os=ios&zbkvc=21 * *///object OnlineState2RedisTrace extends FireStreaming with Logging { private val regex = DataTable.getFilterRegex(Map("homework_fudao" -> Array("tblOnlineStat")), true) private val cmdList = List(IN, OUT) private val ERROR_KEY = "assistant_online_state_error_data_list" override def handle(ssc: StreamingContext): Unit = { val concurrentNumber = ssc.sparkContext.getConf.getInt("spark.onlinestate.concurrent.number", 5) val redisEndpoint = new CodisEndPoint(ssc.sparkContext.getConf) val sink = new AssistantKafkaSink(ssc.sparkContext) val sparkConf = ssc.sparkContext.getConf val esTrace = new ElasticTracing(sparkConf) val source = new KafkaDirectSource[String, String](ssc) val lines: DStream[DataTable] = source.getDStream(_.value()).map(JsonUtil.toDataTable) .filter(filter) .filter(_.TYPE == "I") .filter(filterProduct) .filter(filterCmd) lines.flatMap(convert(_, redisEndpoint)) .foreachRDD((rdd, time) => { val totraceIN: RDD[TracedData] = rdd.map(os => { TracedData(s"${os.uid}_${os.lessonId}_online_in", os, os.courseId, os.lessonId, os.cmd,"OnlineState2RedisTrace_in",os.dt) }) esTrace.actionTrace(totraceIN, "trace_test_onlinestat_in") val sinkTmp: RDD[SendData] = rdd.mapPartitions(sb1 => { compute(sb1, redisEndpoint,sink) }) sinkTmp.map(x => (x.uid, JsonUtil.toJson(List(KAFKA_LESSON_ATTEND_KEY, x)))).foreach({ case (k, v) => sink.sendData(k, v) }) val totraceOut:RDD[TracedData] = sinkTmp.map(tupleSink => { TracedData(s"${tupleSink.uid}_${tupleSink.lessonId}_online_out", tupleSink, tupleSink.courseId,tupleSink.uid, tupleSink.lessonId,"OnlineState2RedisTrace_out") }) esTrace.actionTrace(totraceOut,"sbl9") source.updateOffsets(time.milliseconds) }) } private def compute(iter: Iterator[OnlineState], rp: CodisEndPoint, sink: AssistantKafkaSink): Iterator[SendData] = { iter.flatMap(x => action(x, rp)) } private def action(os: OnlineState, rp: CodisEndPoint): Option[SendData] = os.cmd match { /* 进入课堂逻辑 *///    case IN => inClassroom(os, rp) /* 退出课堂逻辑 *///    case OUT => outClassroom(os, rp) } /** * 进入课堂时处理函数 * 检查redis中是否已经存在数据，不存在则写入 * 存在则 检查已存在数据状态是否为退出，若是退出 则更新状态和时间，否则不操作 *///  private def inClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => // 收到用户进入行为时将此次动作保存下来 val attendTable = getAt(onlineState, redis) val attendAction = AttendAction(IN, onlineState.time) atAllWriteRedis(attendTable.setAction(attendAction), redis) None }(CodisUtil.connect(rp)) } /* 退出课堂时处理函数 *///  private def outClassroom(onlineState: OnlineState, rp: CodisEndPoint): Option[SendData] = { safeClose { redis => val sd = if (redis.hexists(LESSON_KEY, onlineState.lessonId)) { val lt = getLt(onlineState.lessonId, redis) if (lt.startTime <= onlineState.time) { // 退出课堂时间大于等于开课时间，表明是开课后退出 val at = getAt(onlineState, redis) val aa = AttendAction(OUT, onlineState.time) val tid = getTid(lt.lessonId, redis) val sendData = at.compute(aa, lt).map(x => createSendData(tid, x, lt, "OnlineStateTraceSFFNB9")) atWriteRedis(at, redis) atTmpDelRedis(onlineState.lessonId, onlineState.uid, redis) sendData } else { // 退出课堂时间小于开课时间，表明是课程未开始前退出，不做任何计算 atDelRedis(lt.lessonId, onlineState.uid, redis) atTmpDelRedis(lt.lessonId, onlineState.uid, redis) None } } else None sd }(CodisUtil.connect(rp)) } /* 从redis中获取LessonTable *///  def getLt(lid: String, redis: Jedis): LessonTable = { // 这种写法是为了兼容新老 LessonTable 数据结构 Try(JsonUtil.toAny[LessonTable](redis.hget(LESSON_KEY, lid))) .getOrElse { val lo = JsonUtil.toAny[LessonTableOld](redis.hget(LESSON_KEY, lid)) val forceStopTime = lo.stopTime + 15 * 60 val ft = lo.finishTime val finishTime = if (ft == 0) forceStopTime else if (ft > forceStopTime) forceStopTime else ft LessonTable(lo.lessonId, lo.lessonName, lo.startTime, lo.stopTime, finishTime, ft == 0) } } /* 从redis中获取AttendTable 当redis中不能存在时初始化一个 *///  private def getAt(os: OnlineState, redis: Jedis): AttendTable = Try { val k = s"$ONLINE_STATE_KEY${os.lessonId}" JsonUtil.toAny[AttendTable](redis.hget(k, os.uid)) }.getOrElse(AttendTable(os.uid, os.lessonId, os.courseId)) /* AttendTable 写入redis 临时到课表 *///  private def atTmpWriteRedis(at: AttendTable, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY${at.lessonId}" redis.hset(tmpK, at.uid, at.toString) } /* AttendTable 写入redis到课表 *///  def atWriteRedis(at: AttendTable, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY${at.lessonId}" redis.hset(k, at.uid, at.toString) } /* AttendTable 写入redis到课表和临时到课表 *///  private def atAllWriteRedis(at: AttendTable, redis: Jedis): Unit = { atWriteRedis(at, redis) atTmpWriteRedis(at, redis) } /* AttendTable 从redis到课表中删除 *///  def atDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val k = s"$ONLINE_STATE_KEY$lid" redis.hdel(k, uid) } /* AttendTable 从 redis 临时到课表中删除 *///  def atTmpDelRedis(lid: String, uid: String, redis: Jedis): Unit = { val tmpK = s"$IN_ONLINE_STATE_KEY$lid" redis.hdel(tmpK, uid) } /* 获取老师ID *///  private def getTid(lid: String, redis: Jedis): String = redis.hget(TEACHER_LESSON_KEY, lid) /* 将Datatable转换成OnlineState数据结构 *///  private def convert(dt: DataTable, rp: CodisEndPoint): Option[OnlineState] = { Try { val nv = dt.getNewValues() val uid = nv("uid").toString val cmd = nv("cmdno").toString val time = nv("stime").toString.toLong val ext = Utils.paramToMap(nv("extra").toString) val cid = ext("courseId") val lid = ext("lessonId") OnlineState(uid, cid, lid, cmd, time,dt.toString) } match { case Success(value) => Some(value) case Failure(exception) => RedisConnectionPool.safeClose(redis => { redis.lpush(ERROR_KEY, s""" {"data":${JsonUtil.toJson(dt)}, "error":${exception.getMessage}} """) })(CodisUtil.connect(rp)) None } } def createSendData(tid: String, at: AttendTable, lt: LessonTable, proc: String): SendData = { SendData(at.uid, at.lessonId, at.courseId, lt.lessonName, lt.startTime, lt.stopTime, tid, at.tmpAttendLen >= 30 * 60, at.tmpAttendLen >= 5 * 60, at.tmpAttendLen, at.tmpAttendLen.toDouble / (lt.stopTime - lt.startTime) > 3.0 / 4, proc) } private def filter(dt: DataTable) = DataTable.filterTable(dt, regex) private def filterProduct(dt: DataTable) = Try(dt.getNewValues()("product").toString == "fudao").getOrElse(false) private def filterCmd(dt: DataTable) = Try(cmdList.contains(dt.getNewValues()("cmdno").toString)).getOrElse(false) }
//package sakura.streaming import com.homework.bs.assistant.ConstantConfig._ import com.homework.da.format.DataTable import com.homework.da.