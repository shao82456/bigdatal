######################################################
#                                                    #
#               spark process run.sh                 #
#                   user config                      #
#                                                    #
######################################################
#必须设置,执行class的全包名称
spark.run.main=sakura.streaming.TraceDemo
#必须设置,包含main class的jar包名称
#jar文件必须包含在lib.path当中
spark.run.main.jar=fire-sparkl-1.0.jar
#提供给执行class的命令行参数,多个参数之间用逗号隔开,参数中不能包含空格等空白符
#Ex:param1,param2,..
spark.run.self.params=
#用户代码依赖jar包的所在目录
#可以是绝对路径,也可以是相对此配置文件的相对路径,相对路径会自动补全
spark.run.lib.path=lib
######################################################
#                                                    #
#                spark self config                   #
#                                                    #
######################################################
#执行集群设置,不用设置,一般使用YARN
spark.master=yarn
#YARN部署模式
#default=cluster
#spark.submit.deployMode=cluster
#spark-streaming每个批次间隔时间
#default=300
spark.batch.duration=30
#spark on yarn的任务提交队列
#default=default
spark.yarn.queue=zebra
#spark 任务名称配置,建议保持任务名称全局唯一
#这样可以在设计任务失败的时候根据名称做一些唯一处理
#不设置使用类全名.App
spark.app.name=testSyncES.shaoff
#spark网络序列化方式,默认是JavaSerializer,可针对所有类型但速度较慢
#这里使用推荐的Kryo方式
#kafka-0.10必须使用此方式
spark.serializer=org.apache.spark.serializer.KryoSerializer
#++++++++++++++++++++++Driver节点相关配置+++++++++++++++++++++++++++
#Driver节点使用内存大小设置
#default=512M
spark.driver.memory=1024M
#Driver节点使用的cpu个数设置
#default=1
spark.driver.cores=1
#Driver节点构建时spark-jar和user-jar冲突时优先使用用户提供的,这是一个实验性质的参数只对cluster模式有效
#default=false
spark.driver.userClassPathFirst=true
#++++++++++++++++++++++Executor节点相关配置+++++++++++++++++++++++++
#Executor个数设置
#default=1
spark.executor.instances=1
#Executor使用cpu个数设置
#default=1
spark.executor.cores=1
#Executor使用内存大小设置
#default=512MB
spark.executor.memory=512MB
#同driver节点配置作用相同,但是是针对executor的
#default=false
spark.executor.userClassPathFirst=true
#++++++++++++++++++++++++Executor动态分配相关配置++++++++++++++++++++
#Executor动态分配的前置服务
#default=false
spark.shuffle.service.enabled=true
#服务对应的端口,此端口服务是配置在yarn-site中的,由NodeManager服务加载启动
#default=7337
spark.shuffle.service.port=7337
#配置是否启用资源动态分配,此动态分配是针对executor的,需要yarn集群配置支持动态分配
#default=false
spark.dynamicAllocation.enabled=true
#释放空闲的executor的时间
#default=60s
spark.dynamicAllocation.executorIdleTimeout=60s
#有缓存的executor空闲释放时间
#default=infinity(默认不释放)
spark.dynamicAllocation.cachedExecutorIdleTimeout=-1
#初始化executor的个数,如果设置spark.executor.instances谁小用谁
#default=minExecutors(不设置使用此项配置值)
spark.dynamicAllocation.initialExecutors=1
#executor动态分配可分配最大数量
#default=infinity
spark.dynamicAllocation.maxExecutors=60
#executor动态收缩的最小数量
#default=0
spark.dynamicAllocation.minExecutors=1
#批次调度延迟多长时间开始增加executor
#default=1s
spark.dynamicAllocation.schedulerBacklogTimeout=1s
#同上,但是是针对之后的请求
#default=SchedulerBacklogTimeout(不设置使用此项配置值)
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=1s
######################################################
#                                                    #
#             Fire Spark Kafka Source                #
#                   base config                      #
#                                                    #
######################################################
spark.yarn.am.extraJavaOptions=-Dhdp.version=2.5.0.0-1245
spark.driver.extraJavaOptions=-Dhdp.version=2.5.0.0-1245 -Dlog4j.configuration=file:log4j.properties
spark.executor.extraJavaOptions=-Dlog4j.configuration=file:log4j.properties

#spark.source.kafka.consumer后面的配置是标准kafka配置
#kafka消费的topics配置,可以配置多个,每个topic之间用逗号[,]隔开
#default=
spark.source.kafka.consumer.topics=binlog_rds_yike_dianxiao
#kafka consumer的group id.
#default=z.cloud.kafka.consumer.001
spark.source.kafka.consumer.group.id=lecDataSync.t2
#kafka集群的主机和端口号,可以配置多个,每个主机之间用逗号[,]隔开
#default=
spark.source.kafka.consumer.bootstrap.servers=192.168.145.199:9092
#第一次消费kafka topic的时候指定从什么位置消费 有两个可选值latest[最新位置],earliest[最早位置]
#default=earliest
spark.source.kafka.consumer.auto.offset.reset=earliest
#spark消费kafka的时候如何管理offset 这里可选的值有三种hbase,redis,kafka每种值对应一种存储方式
#default=kafka
spark.source.kafka.offset.store.type=redis
spark.source.kafka.offset.store.redis.hosts=10.63.88.39
spark.source.kafka.offset.store.redis.port=6379
spark.source.kafka.offset.store.redis.auth=YsyhL9t
spark.source.kafka.offset.store.redis.dbnum=0
spark.source.kafka.offset.store.redis.timeout=3000
#自定义spark管理kafka offset的方法,需要指定一个自定义类的名称
#spark.source.kafka.offset.store.class=none
#新版本kafka使用的key序列化方式
#default=java.Serialization
spark.source.kafka.consumer.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#最新版kafka使用的value序列化方式
#default=java.Serialization
spark.source.kafka.consumer.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#获取一次数据的最大长度,此值的大小需要kafka server端支持
#default=10485760
spark.source.kafka.consumer.max.partition.fetch.bytes=10485760
#获取一次数据请求的最大等待时间
#default=3000
spark.source.kafka.consumer.fetch.max.wait.ms=3000

#批次监控
spark.streaming.extraListeners=com.homework.da.listener.CongestionMonitor,com.homework.da.listener.NumRecordMonitor
spark.alert.ding=https://oapi.dingtalk.com/robot/send?access_token=dec3b1a3afb0b9f48985c35f0edc8ab373948e50d9d3630382a893f6f99fff03
spark.alert.mail=shaofengfeng@zuoyebang.com
spark.alert.mobile=17150012018
spark.bm.notAlertRange=21-08

#es-spark
spark.es.nodes=10.63.19.49,10.63.19.54,10.63.108.16,10.63.94.46,10.63.94.19
spark.es.port=8012

spark.yarn.historyServer.address=data-hadoop-32-110.bjyz.zybang.com:18081
spark.eventLog.dir=hdfs:///spark2-history/
spark.eventLog.enabled=true

spark.streaming.kafka.maxRatePerPartition=5000

spark.es.uri=http://192.168.33.115:9200
