######################################################
#                                                    #
#               spark process run.sh                 #
#                   user config                      #
#                                                    #
######################################################
#必须设置,执行class的全包名称
spark.run.main=com.homework.bs.LecAggregation
#必须设置,包含main class的jar包名称
#jar文件必须包含在lib.path当中
spark.run.main.jar=lec-2.0.jar
#提供给执行class的命令行参数,多个参数之间用逗号隔开,参数中不能包含空格等空白符
#Ex:param1,param2,..
spark.run.self.params=
#用户代码依赖jar包的所在目录
#可以是绝对路径,也可以是相对此配置文件的相对路径,相对路径会自动补全
spark.run.lib.path=lib
######################################################
#                                                    #
#                spark self config                   #
#                                                    #
######################################################
#执行集群设置,不用设置,一般使用YARN
spark.master=yarn
#YARN部署模式
#default=cluster
spark.submit.deployMode=cluster
#spark-streaming每个批次间隔时间
#default=300
spark.batch.duration=60
#spark on yarn的任务提交队列
#default=default
spark.yarn.queue=realtime
#spark 任务名称配置,建议保持任务名称全局唯一
#这样可以在设计任务失败的时候根据名称做一些唯一处理
#不设置使用类全名.App
spark.app.name=LecAgg1.shaoff
#spark网络序列化方式,默认是JavaSerializer,可针对所有类型但速度较慢
#这里使用推荐的Kryo方式
#kafka-0.10必须使用此方式
spark.serializer=org.apache.spark.serializer.KryoSerializer
#++++++++++++++++++++++Driver节点相关配置+++++++++++++++++++++++++++
#Driver节点使用内存大小设置
#default=512M
spark.driver.memory=512M
#Driver节点使用的cpu个数设置
#default=1
spark.driver.cores=1
#Driver节点构建时spark-jar和user-jar冲突时优先使用用户提供的,这是一个实验性质的参数只对cluster模式有效
#default=false
spark.driver.userClassPathFirst=false
#++++++++++++++++++++++Executor节点相关配置+++++++++++++++++++++++++
#Executor个数设置
#default=1
spark.executor.instances=20
#Executor使用cpu个数设置
#default=1
spark.executor.cores=1
#Executor使用内存大小设置
#default=512MB
spark.executor.memory=1024MB
#同driver节点配置作用相同,但是是针对executor的
#default=false
spark.executor.userClassPathFirst=false
#++++++++++++++++++++++++Executor动态分配相关配置++++++++++++++++++++
#Executor动态分配的前置服务
#default=false
spark.shuffle.service.enabled=false
#服务对应的端口,此端口服务是配置在yarn-site中的,由NodeManager服务加载启动
#default=7337
spark.shuffle.service.port=7337
#配置是否启用资源动态分配,此动态分配是针对executor的,需要yarn集群配置支持动态分配
#default=false
spark.dynamicAllocation.enabled=false
#释放空闲的executor的时间
#default=60s
spark.dynamicAllocation.executorIdleTimeout=60s
#有缓存的executor空闲释放时间
#default=infinity(默认不释放)
spark.dynamicAllocation.cachedExecutorIdleTimeout=-1
#初始化executor的个数,如果设置spark.executor.instances谁小用谁
#default=minExecutors(不设置使用此项配置值)
spark.dynamicAllocation.initialExecutors=1
#executor动态分配可分配最大数量
#default=infinity
spark.dynamicAllocation.maxExecutors=60
#executor动态收缩的最小数量
#default=0
spark.dynamicAllocation.minExecutors=1
#批次调度延迟多长时间开始增加executor
#default=1s
spark.dynamicAllocation.schedulerBacklogTimeout=1s
#同上,但是是针对之后的请求
#default=SchedulerBacklogTimeout(不设置使用此项配置值)
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=1s


#es-spark
spark.es.write.operation=upsert
spark.es.scroll.size=10000
spark.es.input.use.sliced.partitions=false
spark.es.input.max.docs.per.partition=100000
spark.es.resource.write=media_type
spark.es.batch.size.entries=5000
spark.es.batch.write.refresh=false

#权限相关设置
spark.es.nodes=es-cn-st21owhm5000fbt5e.elasticsearch.aliyuncs.com
spark.es.port=9200
spark.es.nodes.wan.only=true
spark.es.net.http.auth.user=lecspark
spark.es.net.http.auth.pass=lecspark

#history
#spark.yarn.historyServer.address=data-hadoop-32-110.bjyz.zybang.com:18081
#spark.eventLog.dir=hdfs:///spark2-history/
#spark.eventLog.enabled=true

#lec相关
spark.lec.task=call
#spark.sql.autoBroadcastJoinThreshold=104857600
